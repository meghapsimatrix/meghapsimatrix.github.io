---
title: "What is Meta-Analysis?"
author: "Megha Joshi"
date: 2021-06-21
categories: ["R"]
tags: ["meta-analysis", "heterogeneity", "common effects", "fixed effects", "random effects", "meta-regression"]
editor_options: 
  markdown: 
    wrap: 72
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>Scientific researchers tend to produce literature on the same topic
either to replicate or extend prior studies or due to a lack of
awareness of prior evidence (Hedges &amp; Cooper, 2009). Results across
studies tend to vary, even when researchers try to replicate studies,
due to differences in sample characteristics, research designs, analytic
strategies or sampling error (Hedges &amp; Cooper, 2009).</p>
<p>Meta-analysis is a set of statistical techniques for synthesizing
results from multiple primary studies on a common topic. Meta-analysis
can be used to synthesize effect estimates from randomized or
quasi-experimental studies, and correlations between variables from
descriptive studies.</p>
<p>The three major goals of meta-analysis include:</p>
<ol style="list-style-type: decimal">
<li><p>summarizing effect size estimates across studies</p></li>
<li><p>characterizing variability in effect sizes across studies</p></li>
<li><p>explaining the variability in the effect sizes</p></li>
</ol>
<p>The three goals of meta-analysis are discussed below.</p>
<div id="summarizing-effect-sizes" class="section level2">
<h2>1. Summarizing effect sizes</h2>
<p>The first major goal of meta-analysis is to summarize effect size
estimates across multiple studies to estimate the average effect of an
intervention or the average measure of the relationship between two
variables (Konstantopoulos &amp; Hedges, 2019). Let <span class="math inline">\(m\)</span> denote the number of
studies in a meta-analysis, with each study contributing one effect size
estimate, <span class="math inline">\(T_i\)</span> for <span class="math inline">\(i = 1,…,m\)</span>. Below, let <span class="math inline">\(w_i\)</span> indicate some general
weight. Effect size estimates can be pooled as follows (Konstantopoulos
&amp; Hedges, 2019):</p>
<p><span class="math display">\[\hat{\mu} = \frac{\sum_{i= 1}^{m} w_i T_i}{\sum_{i= 1}^{m} w_i}\]</span></p>
<p>One way to pool effect size estimates is by weighing them by the inverse
of their variance estimates; these weights denote the precision of the
estimated effect sizes (Viechtbauer, 2007). The calculation of the
inverse variance weights depends on certain assumptions which are
discussed below.</p>
<div id="common-and-fixed-effects-models" class="section level3">
<h3>Common and Fixed Effects Models</h3>
<p>One assumption is the identical parameters assumption underlying the
common effect model. This assumption states that one true effect size
underlies all of the studies (Rice et al., 2018). An alternative
assumption is the independent parameters assumption underlying the fixed
effects model. This assumption treats the set of studies in a
meta-analysis as all of the studies in the population of interest (Rice
et al., 2018). When using the common effect and fixed effects models,
the inverse variance weights can be calculated as
<span class="math inline">\(w_i = 1/ \hat{\sigma_{i}}^2\)</span>, where <span class="math inline">\(\hat{\sigma}_i^2\)</span> denotes the
sampling error in the estimation of the effect sizes (Konstantopoulos &amp;
Hedges, 2019).</p>
</div>
<div id="random-effects-model" class="section level3">
<h3>Random Effects Model</h3>
<p>Unlike the fixed effects model, the random effects model treats the set
of studies in a meta-analysis as a sample of all possible studies in the
population of interest (Higgins et al., 2009; Konstantopoulos &amp; Hedges,
2019). The variance of the effect sizes between studies is denoted by
<span class="math inline">\(\tau^2\)</span> (Higgins et al., 2009; Konstantopoulos &amp; Hedges, 2019). When
using the random effects model, the inverse variance weights can be
calculated as the inverse of the sum of the two variance components,
<span class="math inline">\(w_i = 1/(\hat{\tau}^2 + \hat{\sigma_{i}}^2)\)</span>, where <span class="math inline">\(\hat\tau^2\)</span> is
some estimate of the between-study variance (Konstantopoulos &amp; Hedges,
2019).</p>
</div>
</div>
<div id="characterizing-variation-in-effect-sizes" class="section level2">
<h2>2. Characterizing Variation in Effect Sizes</h2>
<p>A commonly used statistic to characterize the variation in effect sizes
is the <span class="math inline">\(I^2\)</span> statistics. However, Borenstein et al. (2017) argued that
<span class="math inline">\(I^2\)</span> values do not really capture the variation in effects between
studies. For more discussion on the trickiness in interpreting <span class="math inline">\(I^2\)</span>
values, see my blog post
<a href="https://meghapsimatrix.com/post/i_squared/">here</a>.</p>
<p>An absolute measure of heterogeneity that can be used instead to
quantify between-study heterogeneity is <span class="math inline">\(\tau^2\)</span>. It is a descriptive
statistic that denotes the estimated variation in the true effects or,
as Viechtbauer (2007) described it, the estimated variance of the random
variable producing the true effect sizes.</p>
</div>
<div id="explaining-variation-in-effects" class="section level2">
<h2>3. Explaining Variation in Effects</h2>
<p>In addition to pooling effect size estimates and characterizing
variability in effect sizes, meta-analysts often want to examine what
factors explain or are associated with the variability. Identifying
answers to such questions can clarify whether an intervention is
effective for groups of interest, and whether the intervention should be
developed further to be more effective for target populations under
relevant conditions.</p>
<p>To explain variability in the effect sizes, a meta-regression model is
generally used. Let <span class="math inline">\(T_i\)</span> denote effect size estimate <span class="math inline">\(i\)</span>, <span class="math inline">\(p\)</span> denote
the number of regression parameters, <span class="math inline">\(x_{i1}, … ,x_{i,p-1}\)</span> denote a set
of moderator values associated with effect size estimate <span class="math inline">\(i\)</span>,
<span class="math inline">\(\beta_0, …, \beta_{p-1}\)</span> denote a vector of regression coefficients,
and <span class="math inline">\(\epsilon_i\)</span> denote the error term (Konstantopoulos &amp; Hedges, 2019).
The meta-regression model can be written as follows:</p>
<p><span class="math display">\[
{T}_i = \beta_0 + x_{i1} \beta_1 \, + \,  , … , \, + \, x_{i,p-1}\beta_{p-1} + {\epsilon}_i
\]</span></p>
<p>A random effects weighted least squares meta-regression model can be
used to estimate the parameters in the equation above. An intercept-only
model can be used to estimate the overall average effect size. A
statistically significant test of a regression coefficient for a
moderator would indicate that the effects of a treatment or intervention
depend on the level of the moderator—that the moderator explains
statistically significant variation in the effect sizes.</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<p>Borenstein, M., Higgins, J. P., Hedges, L. V., &amp; Rothstein, H. R.
(2017). Basics of meta-analysis: I2 is not an absolute measure of
heterogeneity. <em>Research Synthesis Methods, 8</em> (1), 5–18.</p>
<p>Hedges, L. V., &amp; Cooper, H. M. (2009). Research synthesis as a
scientific process. <em>The handbook of research synthesis and
meta-analysis</em>.</p>
<p>Higgins, J. P., Thompson, S. G., &amp; Spiegelhalter, D. J. (2009). A
re-evaluation of random-effects meta-analysis. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society), 172</em> (1),
137–159.</p>
<p>Konstantopoulos, S., &amp; Hedges, L. V. (2019). Statistically analyzing
effect sizes: Fixed-and random-effects models. <em>The Handbook of Research
Synthesis and Meta-Analysis</em>, 245–279.</p>
<p>Rice, K., Higgins, J. P., &amp; Lumley, T. (2018). A re-evaluation of fixed
effect (s) meta-analysis. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>181</em> (1), 205–227.</p>
<p>Viechtbauer, W. (2007). Accounting for heterogeneity via random-effects
models and moderator analyses in meta-analysis. <em>Zeitschrift für
Psychologie/Journal of Psychology</em>, <em>215</em> (2), 104–121.</p>
</div>
<div id="author-bio" class="section level2">
<h2>Author Bio</h2>
<p><a href="meghapsimatrix.com"><em>Megha Joshi</em></a> <em>is the Graduate Student
Member-at-Large for the SRMA SIG. She has a PhD in Quantitative Methods
from The University of Texas at Austin.</em></p>
<p><em>This post is based on excerpts from the author’s dissertation.</em></p>
</div>
